{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "evaluate_nuclear.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_341Js7IMN1h",
        "colab_type": "text"
      },
      "source": [
        "#### Install dependencies - everything else should be installed automatically by colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzTCC-An6OMG",
        "colab_type": "code",
        "outputId": "2596d723-415d-409f-e164-d734f6a8cfae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "source": [
        "!pip install tifffile\n",
        "!pip install --upgrade tensorflow==1.13.1\n",
        "# !pip install numpy==1.14.6"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tifffile\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/96/2fcac22c806145b34e682e03874b490ae09bc3e48013a0c77e590cd6be29/tifffile-2019.7.26-py2.py3-none-any.whl (131kB)\n",
            "\r\u001b[K     |██▌                             | 10kB 14.2MB/s eta 0:00:01\r\u001b[K     |█████                           | 20kB 2.3MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 30kB 3.2MB/s eta 0:00:01\r\u001b[K     |██████████                      | 40kB 2.1MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 51kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 61kB 3.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 71kB 3.6MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 81kB 4.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 92kB 4.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 102kB 3.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 112kB 3.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 122kB 3.5MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from tifffile) (1.17.4)\n",
            "Installing collected packages: tifffile\n",
            "Successfully installed tifffile-2019.7.26\n",
            "Collecting tensorflow==1.13.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/77/63/a9fa76de8dffe7455304c4ed635be4aa9c0bacef6e0633d87d5f54530c5c/tensorflow-1.13.1-cp36-cp36m-manylinux1_x86_64.whl (92.5MB)\n",
            "\u001b[K     |████████████████████████████████| 92.5MB 23kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.17.4)\n",
            "Collecting tensorflow-estimator<1.14.0rc0,>=1.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bb/48/13f49fc3fa0fdf916aa1419013bb8f2ad09674c275b4046d5ee669a46873/tensorflow_estimator-1.13.0-py2.py3-none-any.whl (367kB)\n",
            "\u001b[K     |████████████████████████████████| 368kB 43.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (0.33.6)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (0.8.1)\n",
            "Requirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.15.0)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (0.8.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (3.10.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (0.2.2)\n",
            "Collecting tensorboard<1.14.0,>=1.13.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/39/bdd75b08a6fba41f098b6cb091b9e8c7a80e1b4d679a581a0ccd17b10373/tensorboard-1.13.1-py3-none-any.whl (3.2MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2MB 35.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.13.1) (1.0.8)\n",
            "Collecting mock>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/05/d2/f94e68be6b17f46d2c353564da56e6fb89ef09faeeff3313a046cb810ca9/mock-3.0.5-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.13.1) (41.4.0)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.14.0,>=1.13.0->tensorflow==1.13.1) (3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==1.13.1) (2.8.0)\n",
            "Installing collected packages: mock, tensorflow-estimator, tensorboard, tensorflow\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow 1.15.0\n",
            "    Uninstalling tensorflow-1.15.0:\n",
            "      Successfully uninstalled tensorflow-1.15.0\n",
            "Successfully installed mock-3.0.5 tensorboard-1.13.1 tensorflow-1.13.1 tensorflow-estimator-1.13.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iihbqx6Bkp2_",
        "colab_type": "code",
        "outputId": "144e1e73-8d16-4415-e28e-1a0aeedffee5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.losses import binary_crossentropy\n",
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "import tifffile\n",
        "\n",
        "print('TENSORFLOW VERSION ', tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
            "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "TENSORFLOW VERSION  1.13.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKtaF8zRpbBS",
        "colab_type": "code",
        "outputId": "d1d5da7a-3476-491a-b085-6dbb6a1d5bc7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9AHaCsTkp3E",
        "colab_type": "text"
      },
      "source": [
        "#### Config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SlLC7ZnMWMY",
        "colab_type": "text"
      },
      "source": [
        "# **IMPORTANT**\n",
        "You must modify the following `training_paths` with tuples of form `[(PATH_TO_TRAINING_X, PATH_TO_TRAINING_Y), ...]`.\n",
        "\n",
        "You must also modify `validation_data` with your own validation data paths, in the same tuple form as above.\n",
        "\n",
        "The config parameters must be the same as in the train notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfRxgH0Mkp3F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCH_SIZE = 16\n",
        "PATCH_SHAPE = (12, 256, 256)\n",
        "NUM_LAYERS = 4\n",
        "START_CH = 32\n",
        "OVERLAP_X_Y = PATCH_SHAPE[1]//4\n",
        "OVERLAP_Z = PATCH_SHAPE[0]//4\n",
        "DROPOUT = 0.3\n",
        "model_fn = f\"gdrive/My Drive/models/{NUM_LAYERS}L_{START_CH}ch_{PATCH_SHAPE}_{DROPOUT}DROPOUT iter25\"\n",
        "\n",
        "\n",
        "# DATA AUGMENTATION CONFIGURATION\n",
        "ROTATION_RANGE = 0  # +/- ~90˚\n",
        "ZOOM_RANGE = 0.05 # +/- ~10% zoom\n",
        "CONTRAST_RANGE = 0.1 # +/- ~10% constrast\n",
        "BRIGHTNESS_RANGE = 0.1 # +/- ~10% brightness\n",
        "BLUR_RANGE = 0.2 # blur +/- 2 sigma\n",
        "NOISE = 12  # range of noise +/- 12 brightness"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipLm5LzWkp3K",
        "colab_type": "text"
      },
      "source": [
        "#### Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uwL09bykp3L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def dice_coef(y_true, y_pred, smooth=1):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    \n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "def dice_coef_loss(y_true, y_pred):\n",
        "    return 1-dice_coef(y_true, y_pred)\n",
        "\n",
        "def bce_dice_loss(y_true, y_pred):\n",
        "    return binary_crossentropy(y_true, y_pred) + dice_coef_loss(y_true, y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyVU_wTgv6JO",
        "colab_type": "text"
      },
      "source": [
        "**Data utils**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEf3fwvEv1gH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_random_batch_corner_coordinates(batch_size, region):\n",
        "  \"\"\" @param region: (Z0, Z1, Y0, Y1, X0, X1) return coordniates in high/low range given\n",
        "      @param batch_size: how many random coordinates to generate?\n",
        "\n",
        "      @return: (batch_size, 3) stacks of random (Z, Y, X) coordinates\n",
        "  \"\"\"\n",
        "  r = np.array([[np.random.randint(region[0], region[1] - PATCH_SHAPE[0]),\n",
        "                 np.random.randint(region[2], region[3] - PATCH_SHAPE[1]),\n",
        "                 np.random.randint(region[4], region[5] - PATCH_SHAPE[2])\n",
        "                 ] for _ in range(batch_size)])\n",
        "  return r\n",
        "\n",
        "\n",
        "def get_image_patch(image, corner_coordinate):\n",
        "  \"\"\"\n",
        "\n",
        "  :param image:\n",
        "  :param corner_coordinate:\n",
        "  :param patch_shape:\n",
        "  :return:\n",
        "  \"\"\"\n",
        "  patch = image[corner_coordinate[0]:corner_coordinate[0] + PATCH_SHAPE[0],\n",
        "                corner_coordinate[1]:corner_coordinate[1] + PATCH_SHAPE[1],\n",
        "                corner_coordinate[2]:corner_coordinate[2] + PATCH_SHAPE[2]]\n",
        "  return patch\n",
        "\n",
        "def normalize_batch(batch):\n",
        "  \"\"\" normalize X batch by subbing mean then dividing by std\n",
        "      normalized over the 0 axis (patch-wise mean and std)\n",
        "  \"\"\"\n",
        "  mean = batch.mean(axis=(1, 2, 3), keepdims=True)\n",
        "  std = batch.std(axis=(1, 2, 3), keepdims=True)\n",
        "  batch = (batch - mean) / (std + 0.0001)\n",
        "  return batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyDCjzhBkp3e",
        "colab_type": "text"
      },
      "source": [
        "#### Make patch-wise predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EEJG7UEcMna",
        "colab_type": "code",
        "outputId": "1c8245c8-138c-41d0-dbc1-749c99803528",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "# you may want to load a different model - make sure that patch size is correct\n",
        "model_filename = model_fn + '.hdf5'\n",
        "print(\"Loading model: \" + model_filename)\n",
        "model = load_model(model_filename, custom_objects={'dice_coef_loss': dice_coef_loss})\n",
        "\n",
        "model.compile(\n",
        "# optimizer=tf.keras.optimizers.Adam(lr=0.001),\n",
        "  optimizer=tf.train.AdamOptimizer(learning_rate=0.001),\n",
        "  loss=dice_coef_loss\n",
        ")\n",
        "\n",
        "\n",
        "TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']  # get TPU address\n",
        "tf.logging.set_verbosity(tf.logging.INFO)\n",
        "\n",
        "strategy = tf.contrib.tpu.TPUDistributionStrategy(\n",
        "  tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)\n",
        ")\n",
        "\n",
        "tpu_model = tf.contrib.tpu.keras_to_tpu_model(\n",
        "  model,\n",
        "  strategy=strategy, \n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading model: gdrive/My Drive/models/4L_32ch_(12, 256, 256)_0.3DROPOUT iter25.hdf5\n",
            "WARNING:tensorflow:No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.127.69.194:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 7174341447447038467)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 15389719267837346949)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 10087768657594870198)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 7588794946352429535)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 10740397722808616190)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 921871459131284257)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 12521803315633328546)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 3649907447626521031)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 3166656839713852462)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 7803660088124436611)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 7884547231715109310)\n",
            "WARNING:tensorflow:tpu_model (from tensorflow.contrib.tpu.python.tpu.keras_support) is experimental and may change or be removed at any time, and without warning.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjuUj9nobrWf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split(a, n):\n",
        "  \"\"\" split a list into n chunks of approx equal length \"\"\"\n",
        "  k, m = divmod(len(a), n)\n",
        "  return (a[i * k + min(i, m):(i + 1) * k + min(i + 1, m)] for i in range(n))\n",
        "\n",
        "\n",
        "def run_prediction(model, volume):\n",
        "  \"\"\"\n",
        "  :model: a keras model object\n",
        "  :volume: a 3D image volume (ndarray) to obtain the 3d segmentation map for\n",
        "  \"\"\"\n",
        "\n",
        "  # padding guarantees that the whole volume is convolved over.\n",
        "  padded_volume = np.pad(\n",
        "      volume, \n",
        "      (\n",
        "       (OVERLAP_Z + PATCH_SHAPE[0], OVERLAP_Z + PATCH_SHAPE[0]),\n",
        "       (OVERLAP_X_Y + PATCH_SHAPE[1], OVERLAP_X_Y + PATCH_SHAPE[1]),\n",
        "       (OVERLAP_X_Y + PATCH_SHAPE[2], OVERLAP_X_Y + PATCH_SHAPE[2])\n",
        "      ),\n",
        "      'symmetric'\n",
        "  )\n",
        "  \n",
        "  D, H, W = padded_volume.shape\n",
        "  print(padded_volume.shape)\n",
        "  \n",
        "  grid_coordinates = [\n",
        "      (z, y, x) \n",
        "      for z in range(0, D-PATCH_SHAPE[0], PATCH_SHAPE[0]-(OVERLAP_Z*2))\n",
        "      for y in range(0, H-PATCH_SHAPE[1], PATCH_SHAPE[1]-(OVERLAP_X_Y*2))\n",
        "      for x in range(0, W-PATCH_SHAPE[2], PATCH_SHAPE[2]-(OVERLAP_X_Y*2)) \n",
        "  ]\n",
        "  \n",
        "  result_volume = np.zeros_like(padded_volume, dtype=np.float32)\n",
        "  # split up computation into batches because thats a lot of patches\n",
        "  print(f'Running prediction over {len(grid_coordinates)} patches')\n",
        "  \n",
        "  # make divisible by 8 for tpu\n",
        "  tpu_coords = [grid_coordinates[x:x+128] for x in range(0, len(grid_coordinates)-128, 128)]\n",
        "  \n",
        "  for batch_coordinates in tpu_coords:\n",
        "  \n",
        "    image_patches = []\n",
        "    for corner in batch_coordinates:\n",
        "      image_patch = get_image_patch(padded_volume, corner)\n",
        "      image_patches.append(image_patch)\n",
        "\n",
        "    image_patches = np.array(image_patches)\n",
        "    image_patches = np.moveaxis(image_patches, 1, 3)  # tf --> (N, W, H, D)\n",
        "    normalized_image_patches = normalize_batch(image_patches)\n",
        "\n",
        "    predictions = model.predict(normalized_image_patches)\n",
        "    \n",
        "    \"\"\"\n",
        "    print(predictions.shape)\n",
        "    predictions = predictions[0]\n",
        "    predictions = np.moveaxis(predictions, 2, 0)\n",
        "    print(predictions.shape)\n",
        "    plt.figure(figsize=(20, 20))\n",
        "    plt.imshow(predictions[0]*255, cmap='gray', vmin=0, vmax=255)\n",
        "    plt.show()\n",
        "    return\n",
        "    \"\"\"\n",
        "\n",
        "    for i, (d, h, w) in enumerate(batch_coordinates):\n",
        "      # crop out the patch overlap (remove the perimiter)\n",
        "      p  = np.moveaxis(predictions[i], 2, 0)[\n",
        "        OVERLAP_Z : -OVERLAP_Z, \n",
        "        OVERLAP_X_Y : -OVERLAP_X_Y,\n",
        "        OVERLAP_X_Y : -OVERLAP_X_Y\n",
        "      ]\n",
        "      # insert that crop into the right place in the result image\n",
        "      result_volume[\n",
        "        d + OVERLAP_Z : d + PATCH_SHAPE[0] - OVERLAP_Z, \n",
        "        h + OVERLAP_X_Y : h + PATCH_SHAPE[1] - OVERLAP_X_Y, \n",
        "        w + OVERLAP_X_Y : w + PATCH_SHAPE[2] - OVERLAP_X_Y\n",
        "      ] = p\n",
        "      \n",
        "  \n",
        "  # handle the missing patches from TPU divisible batches\n",
        "  \n",
        "  missing = len(grid_coordinates) % 128\n",
        "  extra_batch = grid_coordinates[len(grid_coordinates)-missing:]\n",
        "  extra_batch += [(0,0,0)] * (128 - missing)\n",
        "\n",
        "  image_patches = []\n",
        "  for corner in extra_batch:\n",
        "    image_patch = get_image_patch(padded_volume, corner)\n",
        "    image_patches.append(image_patch)\n",
        "\n",
        "  image_patches = np.array(image_patches)\n",
        "  image_patches = np.moveaxis(image_patches, 1, 3)  # tf --> (N, W, H, D)\n",
        "  normalized_image_patches = normalize_batch(image_patches)\n",
        "\n",
        "  predictions = model.predict(normalized_image_patches)\n",
        "\n",
        "  for i, (d, h, w) in enumerate(extra_batch[:missing]):\n",
        "    # crop out the patch overlap (remove the perimiter)\n",
        "    p  = np.moveaxis(predictions[i], 2, 0)[\n",
        "      OVERLAP_Z : -OVERLAP_Z, \n",
        "      OVERLAP_X_Y : -OVERLAP_X_Y,\n",
        "      OVERLAP_X_Y : -OVERLAP_X_Y\n",
        "    ]\n",
        "    # insert that crop into the right place in the result image\n",
        "    result_volume[\n",
        "      d + OVERLAP_Z : d + PATCH_SHAPE[0] - OVERLAP_Z, \n",
        "      h + OVERLAP_X_Y : h + PATCH_SHAPE[1] - OVERLAP_X_Y, \n",
        "      w + OVERLAP_X_Y : w + PATCH_SHAPE[2] - OVERLAP_X_Y\n",
        "    ] = p\n",
        "    \n",
        "    \n",
        "  # remove the padding to restore original shape\n",
        "  result_volume = result_volume[\n",
        "      OVERLAP_Z + PATCH_SHAPE[0] : -(OVERLAP_Z + PATCH_SHAPE[0]),\n",
        "      OVERLAP_X_Y + PATCH_SHAPE[1] : -(OVERLAP_X_Y + PATCH_SHAPE[1]),\n",
        "      OVERLAP_X_Y + PATCH_SHAPE[2] : -(OVERLAP_X_Y + PATCH_SHAPE[2]),\n",
        "  ]\n",
        "\n",
        "  return result_volume"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNH0JsTNO2Kg",
        "colab_type": "text"
      },
      "source": [
        "#### Run prediction on whole volume (517, 2048, 2048)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ACzLGW6gE4L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "t = 'gdrive/My Drive/ROI_1656-6756-329.tiff'\n",
        "X_test = tifffile.imread(t)\n",
        "X_test.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C0hkgsoGGmEV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for xx in range(0, 2048, 512):\n",
        "  for yy in range(0, 2048, 512):\n",
        "    start = time.time()\n",
        "    patch = X_test[:, xx:xx+512, yy:yy+512]\n",
        "    patch_prediction = run_prediction(tpu_model, patch)\n",
        "    X_test[:, xx:xx+512, yy:yy+512] = patch_prediction\n",
        "    print(f'Prediciton {xx},{yy} completed in {int(time.time()-start)} seconds')\n",
        "    \n",
        "from os.path import join\n",
        "save_dir = 'gdrive/My Drive/Unlimited/'\n",
        "save_path_raw = join(save_dir, 'WHOLE_3VIEW_EXP_L.tiff')\n",
        "tifffile.imsave(save_path_raw, X_test*255)\n",
        "!zip -r 'gdrive/My Drive/Unlimited/WHOLE_3VIEW_EXP_L.zip' 'gdrive/My Drive/Unlimited/WHOLE_3VIEW_EXP_L.tiff'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o94AWrSRPYE4",
        "colab_type": "text"
      },
      "source": [
        "#### Run prediction on individual ROIs "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Hjpxa0cUK1u",
        "colab_type": "code",
        "outputId": "6b51733f-a159-4612-9f31-c817c2b4950a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "### PREDICT AND SAVE FOR ALL IN DIRECTORY\n",
        "from os import listdir, remove, mkdir\n",
        "from os.path import join, exists\n",
        "from zipfile import ZipFile\n",
        "\n",
        "image_dir = 'gdrive/My Drive/scaled-stacks/'\n",
        "label_dir = 'gdrive/My Drive/scaled-labels-stacks/'\n",
        "save_dir = 'gdrive/My Drive/predictions_individual/'\n",
        "\n",
        "if not exists(save_dir):\n",
        "  mkdir(save_dir)\n",
        "\n",
        "# replace this with listdir(image_dir) to run on all ROIs\n",
        "#paths = ['ROI_2052-5784-112.tiff']\n",
        "#paths = ['roi_test.tif']\n",
        "#paths = ['ROI_3588-3972-1.tiff']\n",
        "paths = ['ROI_1656-6756-329.tiff', 'ROI_3624-2712-201.tiff']\n",
        "\n",
        "\n",
        "for path in paths:\n",
        "  read_path = join(image_dir, path)\n",
        "  X_test = tifffile.imread(read_path)\n",
        "  start = time.time()\n",
        "  test_prediction = run_prediction(tpu_model, X_test)\n",
        "  print(f'Prediciton completed in {int(time.time()-start)} seconds')\n",
        "  \n",
        "  save_path_raw = join(save_dir, path)\n",
        "  tifffile.imsave(save_path_raw, test_prediction)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(283, 1140, 1140)\n",
            "Running prediction over 2254 patches\n",
            "INFO:tensorflow:New input shapes; (re-)compiling: mode=infer (# of cores 8), [TensorSpec(shape=(4, 256, 256, 12), dtype=tf.float32, name='input_1_50')]\n",
            "INFO:tensorflow:Overriding default placeholder.\n",
            "INFO:tensorflow:Remapping placeholder for input_1\n",
            "INFO:tensorflow:Started compiling\n",
            "INFO:tensorflow:Finished compiling. Time elapsed: 37.53628492355347 secs\n",
            "INFO:tensorflow:Setting weights on TPU model.\n",
            "Prediciton completed in 158 seconds\n",
            "(319, 1140, 1140)\n",
            "Running prediction over 2548 patches\n",
            "Prediciton completed in 103 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZO9O0X2fkp3o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def overlay_x_on_y(x, y):\n",
        "  colours = plt.cm.viridis(x)\n",
        "  colours[..., -1] = x * 1\n",
        "  fig = plt.figure(figsize=(7, 7), dpi=180)\n",
        "  ax = fig.add_subplot(111)\n",
        "  ax.grid(False)\n",
        "  plt.imshow(y, 'gray', interpolation='bilinear')\n",
        "  plt.imshow(colours, interpolation='bilinear')\n",
        "  plt.show()\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICCS9tm1kp3s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "overlay_x_on_y(test_prediction[0, :, :], X_test[0, :, :])\n",
        "#overlay_x_on_y(test_prediction[160, :, :], X_test[160, :, :])\n",
        "#overlay_x_on_y(test_prediction[161, :, :], X_test[161, :, :])\n",
        "#overlay_x_on_y(test_prediction[140, :, :], X_test[140, :, :])\n",
        "#overlay_x_on_y(test_prediction[210, :, :], X_test[210, :, :])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3rygPGtXUfWC",
        "colab_type": "code",
        "outputId": "362684dd-d11b-49bc-b334-13131ca8380b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "def iou(ground_truth, prediction):\n",
        "  intersection = ground_truth * ground_truth\n",
        "  union = np.sum(ground_truth) + np.sum(prediction)\n",
        "  score = intersection.sum() / union\n",
        "  return score\n",
        "\n",
        "for path in paths:\n",
        "  read_path = join(label_dir, path)\n",
        "  y_true = np.where(tifffile.imread(read_path) >= 0.5, 1, 0)\n",
        "  print(iou(y_true, test_prediction))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.2086840829512997\n",
            "0.303308746522341\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQuZr94e2Pk-",
        "colab_type": "text"
      },
      "source": [
        "#### Connected component analysis for the removal of noise is best accomplished using the Fiji plugin called MorphoLibJ. "
      ]
    }
  ]
}